{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"E133olOcNouR"},"outputs":[],"source":["### This code will take in a TF list as an excel file and return a pd dataframe of the relevant features and gene region sequences for each start and stop codon of interest.\n","# Contact scro4473@ox.ac.uk for questions and queries\n","\n","## the second part takes care of primers\n","#contact blina4278@ox.ac.uk"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54759,"status":"ok","timestamp":1673623372587,"user":{"displayName":"Giulia Biasi","userId":"09582871698880234500"},"user_tz":0},"id":"ksj8F76d2isQ","outputId":"e13101aa-095e-4487-82e5-7d84f65b1e01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: biopython in /home/user/.local/lib/python3.10/site-packages (1.80)\n","Requirement already satisfied: numpy in /home/user/.local/lib/python3.10/site-packages (from biopython) (1.24.1)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: primer3-py in /home/user/.local/lib/python3.10/site-packages (0.6.1)\n","Defaulting to user installation because normal site-packages is not writeable\n","Collecting pandas\n","  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /home/user/.local/lib/python3.10/site-packages (from pandas) (1.24.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /home/user/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Installing collected packages: pandas\n","Successfully installed pandas-1.5.3\n","Defaulting to user installation because normal site-packages is not writeable\n","Collecting tqdm\n","  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: tqdm\n","Successfully installed tqdm-4.64.1\n"]}],"source":["#Import packages\n","!pip install biopython\n","!pip install primer3-py\n","!pip install pandas\n","!pip install tqdm\n","\n","import pandas as pd\n","from Bio import SeqIO\n","import primer3 as p3\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SX1ay0pOmnDx"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32LUgzhHR1qh"},"outputs":[],"source":["#Functions\n","\n","#ReverseComplement\n","def revComp(inputSeq):\n","  \"\"\"\n","  This function takes an input sequence and returns the reverse complement.\n","\n","  Input: inputSeq in str format\n","  Output: revComp in str format\n","\n","  \"\"\"\n","  complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}\n","  \n","  revComp = \"\"\n","  for base in inputSeq[::-1]:\n","    revComp += complement[(base.upper())]\n","\n","  return revComp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VkzTkR7yuYWJ"},"outputs":[],"source":["#This is the input file containing the TFs we want to query\n","#Imported as a pandas dataframe\n","queryTFsdf = pd.read_excel('/content/drive/My Drive/bioinformatics project/TFs.xlsx')\n","#Ths contains 765 TFs total\n","\n","#This is the .gtf file with annotations for each gene on the reference genome\n","#Note that I'll use these for the info categories of the final pandas df (rather than the transgenic genome annotations)\n","refAnnotationsHeaders = [\"Chromosome\", \"Source\", \"Gene_Region\", \"Start\", \"Stop\", \"Score\", \"Strand\", \"Frame\", \"Attribute\"]\n","refGenomeAnnotation = pd.read_csv(r'/content/drive/My Drive/bioinformatics project/dmel-all-r6.48.gtf', sep = \"\\t\", header = None, index_col = False, names = refAnnotationsHeaders)\n","\n","#This is the FASTA file of the reference genome sequence\n","refSeqPerChromosome = {}\n","for seq in SeqIO.parse(open('/content/drive/My Drive/bioinformatics project/dmel-all-chromosome-r6.48.fasta'), 'fasta'):\n","  refSeqPerChromosome[seq.id] = seq.seq\n","\n","#This is the nos-Cas9 on 2 sequence - use for chromosome 3 only\n","on2SeqPerChromosome = {}\n","for seq in SeqIO.parse(open('/content/drive/My Drive/bioinformatics project/dmel6-nos-Cas9_on_2.fasta'), 'fasta'):\n","  on2SeqPerChromosome[seq.id] = seq.seq\n","\n","#This is the nos-Cas9 on 3 sequence - use for all other chromosomes\n","on3SeqPerChromosome = {}\n","for seq in SeqIO.parse(open('/content/drive/My Drive/bioinformatics project/dmel6-nos-Cas9_on_3.fasta'), 'fasta'):\n","  on3SeqPerChromosome[seq.id] = seq.seq"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IOoB5z9UaE6K"},"outputs":[],"source":["#This is to reformat the \"Attribute\" category in refGenomeAnnotation, to extract Gene_ID, Gene_Symbol, and Transcript ID\n","index = 0\n","\n","#Add new categories to the dataframe\n","refGenomeAnnotation = refGenomeAnnotation.assign(Gene_ID = \"\", Gene_Symbol = \"\", Transcript_ID = \"\")\n","\n","#For each attribute value, extract the gene ID and symbol and add this to the new categories\n","for attribute in refGenomeAnnotation['Attribute']:\n","  fullatt = (refGenomeAnnotation.loc[index][\"Attribute\"]).replace(\";\", \"\")\n","  fullatt = fullatt.replace('\"', \"\")\n","  fullattsplit = fullatt.split(\" \")\n","  refGenomeAnnotation.at[index,\"Gene_ID\"] = fullattsplit[1]\n","  refGenomeAnnotation.at[index,\"Gene_Symbol\"] = fullattsplit[3]\n","  if len(fullattsplit) == 8:\n","    refGenomeAnnotation.at[index,\"Transcript_ID\"] = fullattsplit[5]\n","  index+=1\n","\n","#Delete Attributes category\n","del refGenomeAnnotation[\"Attribute\"]\n","\n","display(refGenomeAnnotation)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5KiXnJquKzwo"},"outputs":[],"source":["#Select only rows that TFs are in, and keep only the start and stop codon gene regions\n","\n","refGenomeAnnotation = refGenomeAnnotation.loc[refGenomeAnnotation[\"Gene_Region\"].isin([\"start_codon\", \"stop_codon\"])]\n","\n","TFsdf = refGenomeAnnotation[[\"Gene_ID\", \"Transcript_ID\", \"Chromosome\", \"Gene_Region\", \"Start\", \"Stop\", \"Strand\"]].loc[refGenomeAnnotation[\"Gene_ID\"].isin(queryTFsdf[\"Flybase_ID\"])]\n","\n","display(TFsdf)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rw4qJX5wL7zQ"},"outputs":[],"source":["#Add reference genome sequence per gene region\n","#This will correspond to 1.3kb upstream and downstream of ATG/stop codon \n","TFsdf = TFsdf.assign(Reference_Seq = \"\", Transgenic_Seq = \"\")\n","\n","#FASTAs for reference and transgenic are in format of a dictionary of chromosome:\"sequence\"\n","\n","for index, rowcontents in TFsdf.iterrows():\n","  if rowcontents[\"Strand\"] == \"+\":\n","\n","    #Define 2.6kb gene region\n","    regionStart = rowcontents[\"Start\"] - 1301\n","    regionStop = rowcontents[\"Stop\"] + 1300\n","\n","    #Add reference sequence\n","    TFsdf.at[index,\"Reference_Seq\"] = str(refSeqPerChromosome[rowcontents[\"Chromosome\"]][regionStart:regionStop])\n","    \n","    #Add appropriate transgenic sequence, depending on the chromosome\n","    if rowcontents[\"Chromosome\"].startswith(\"3\"):\n","      TFsdf.at[index,\"Transgenic_Seq\"] = str(on2SeqPerChromosome[rowcontents[\"Chromosome\"]][regionStart:regionStop])\n","    else:\n","      TFsdf.at[index,\"Transgenic_Seq\"] = str(on3SeqPerChromosome[rowcontents[\"Chromosome\"]][regionStart:regionStop])\n","\n","  if rowcontents[\"Strand\"] == \"-\":\n","\n","    #Define 2.6kb gene region\n","    regionStart = rowcontents[\"Start\"] - 1301\n","    regionStop = rowcontents[\"Stop\"] + 1300\n","\n","    #Add reference sequence\n","    refPosStrandSeq = str(refSeqPerChromosome[rowcontents[\"Chromosome\"]][regionStart:regionStop]) #This is the + strand seq, so goes from end to beginning\n","    TFsdf.at[index,\"Reference_Seq\"] = revComp(refPosStrandSeq)\n","\n","    #Add appropriate transgenic sequence, depending on the chromosome\n","    if rowcontents[\"Chromosome\"].startswith(\"3\"):\n","      transgStrandSeq = str(on2SeqPerChromosome[rowcontents[\"Chromosome\"]][regionStart:regionStop])\n","      TFsdf.at[index,\"Transgenic_Seq\"] = revComp(transgStrandSeq)\n","    else:\n","      transgStrandSeq = str(on3SeqPerChromosome[rowcontents[\"Chromosome\"]][regionStart:regionStop])\n","      TFsdf.at[index,\"Transgenic_Seq\"] = revComp(transgStrandSeq)\n","\n","display(TFsdf)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y4yhzWddpojb"},"outputs":[],"source":["def DesignPrimer(template,stringency,GC_content,max_end_GC,size,GC_clamp,TH_max_hairpin,max_polyx,\n","                 primer_region, primer_type,primer_number):\n"," \n","  '''\n","  THIS FUNCTION CALCULATES A PRIMER GIVEN THE CONDITIONS AND HOW STRICT\n","   THOSE CONDITIONS SHOULD BE\n","\n","  stringency is a list with n elements (i.e., n different stringency levels). Each condition is a \n","  list (or a list of list). The list contains n elements (one for each striengency level). The \n","  innermost list in a list of list contains [min,opt,max]\n","  \n","  '''\n","  if primer_type == \"F\":\n","    left = 1\n","    right = 0\n","  elif primer_type == \"R\":\n","    left = 0\n","    right = 1\n","\n","  primer = p3.bindings.designPrimers(\n","    {\n","        'SEQUENCE_TEMPLATE': template,\n","        'SEQUENCE_INCLUDED_REGION': primer_region, \n","    },\n","    {\n","        'PRIMER_NUM_RETURN':primer_number,\n","\n","        'PRIMER_TASK': \"generic\",\n","        'PRIMER_PICK_LEFT_PRIMER': left,\n","        'PRIMER_PICK_INTERNAL_OLIGO': 0,\n","        'PRIMER_PICK_RIGHT_PRIMER': right,\n","\n","        'PRIMER_MIN_GC': GC_content[stringency][0],\n","        'PRIMER_OPT_GC_PERCENT': GC_content[stringency][1],\n","        'PRIMER_MAX_GC': GC_content[stringency][2],\n","     \n","        'PRIMER_MIN_SIZE': size[stringency][0],\n","        'PRIMER_OPT_SIZE': size[stringency][1],\n","        'PRIMER_MAX_SIZE': size[stringency][2],\n","     \n","        'PRIMER_MAX_END_GC': max_end_GC[stringency],\n","     \n","        'PRIMER_GC_CLAMP': GC_clamp[stringency],    \n","             \n","        'PRIMER_MAX_HAIRPIN_TH':TH_max_hairpin[stringency],\n","    \n","        'PRIMER_MAX_POLY_X': max_polyx[stringency],\n","    })\n","  \n","  return primer\n","\n","\n","def DoIHaveAPrimer(extension,Gene_ID,start_stop,primer_type, primer_name,stringency,primer):\n","  \n","  if extension == 0:\n","    Extended_tag = \"\"\n","  elif extension == 1:\n","    Extended_tag = \"e\"\n","\n","\n","  if primer_type == \"F\":\n","    if primer['PRIMER_LEFT_NUM_RETURNED']>0:\n","      primers_cleanup = {'Gene_ID': Gene_ID,\n","                         'position':start_stop,\n","                         'primer_type': primer_name,\n","                         'primer_sequence': primer['PRIMER_LEFT_0_SEQUENCE'],\n","                         'stringency_level': f'{Extended_tag}{stringency+1}'}\n","      warning_variable = False\n","    else:\n","      primers_cleanup = ()\n","      warning_variable = True\n","\n","  elif primer_type == \"R\":\n","    if primer['PRIMER_RIGHT_NUM_RETURNED']>0:\n","      primers_cleanup = {'Gene_ID': Gene_ID,\n","                         'position':start_stop,\n","                         'primer_type': primer_name,\n","                         'primer_sequence': primer['PRIMER_RIGHT_0_SEQUENCE'],\n","                         'stringency_level': f'{Extended_tag}{stringency+1}'}\n","      warning_variable = False\n","    else:\n","      primers_cleanup = ()\n","      warning_variable = True\n","\n","  return primers_cleanup, warning_variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8fnNscLpxsT"},"outputs":[],"source":["def SixPrimersCalculator(Gene_ID,start_stop,template,primer_name,initial_primer_region,enlarged_primer_region,GC_content,size,max_end_GC,GC_clamp,TH_max_hairpin,max_polyx,stringency_levels):\n","  primers_table = pd.DataFrame() # DataFrame used to save the 6 primers\n","  \n","\n","  for pt in range(0,len(primer_name)): #loop to get as many primers as specified in the primer_name list (here 6)\n","    \n","    # defining what type of primer I am working with \n","    if \"-F\" in primer_name[pt]:\n","      primer_type = \"F\"\n","    elif \"-R\" in primer_name[pt]:\n","      primer_type = \"R\"\n","\n","    # defining how many primer outputs I want to have (one is NOT enough for the special cases)\n","    if ((pt==2) or (pt==3)):  # output is only one primer if we do not care about the exact initial position (i.e., for 4/6 primers)\n","      primer_number = 1000\n","    else:\n","      primer_number = 1\n","\n","   ###############################################################################\n","    # loop to ACTUALLY take care of the primers (one at a time, considering different stringencies)\n","    stringency = 0 #initial condition (most stringent conditions)\n","\n","    safety_net_primer_forward = ()  # empty variables to save HAL-R and HAR-F primers at a random position (BUT still in the right range)\n","    safety_net_primer_reverse = ()  # this is useful in case we can't find any satisfactory primers in the right position\n","    primer_region = initial_primer_region\n","\n","    while stringency<stringency_levels: # TO DO NEXT: must add extra level to go in larger dimensions (with if statement to change the borders soon below)\n","\n","      primer = DesignPrimer(template,stringency,GC_content,max_end_GC,size,GC_clamp,TH_max_hairpin,max_polyx,    # designing the primer\n","                          primer_region[pt], primer_type, primer_number)\n","\n","      if primer_type == \"F\": # necessary only for special cases 2 and 3 - the # of calculated primers allows us to loop over them and choose the best\n","        number_of_calculated_primers = primer['PRIMER_LEFT_NUM_RETURNED']  \n","      elif primer_type == \"R\":\n","        number_of_calculated_primers = primer['PRIMER_RIGHT_NUM_RETURNED']\n","          \n","      ####### special cases -  HAL-R and HAR -F #############\n","      if (pt == 2 or pt == 3): # TO DO NEXT: when we add the extra level this will need to be skipped --> must add and stirngency<stringency level\n","        primers_cleanup = () # empty variable to save the final primer of choice\n","\n","        for sc in range(0,number_of_calculated_primers): # evaluating all the primers obtained\n","\n","            if (pt==2): # HAL-R\n","\n","              # saving a random \"good\" primer as a \"safety net\" in case we can not find any other in the exact position\n","              if safety_net_primer_reverse == ():   # saving of a \"net\" happens only if we find a primer + no primers can get overwritten\n","                safety_net_primer_reverse = primer['PRIMER_RIGHT_0_SEQUENCE'] # saving the first one - for each primer the safety net is overwritten\n","              \n","              temporary_name_string = f'PRIMER_RIGHT_{sc}_SEQUENCE'  \n","              reverse_complement = revComp(primer[temporary_name_string]) # checking position of the primer\n","              primer_position = template.index(reverse_complement)\n","              if (primer_position + len(reverse_complement)) == 1300: \n","                primers_cleanup = {'Gene_ID': Gene_ID, # if the position is correct we choose it!! --> we can now leave the while loop!\n","                                   'position':start_stop,\n","                                   'primer_type': primer_name[pt],\n","                                   'primer_sequence': primer[f'PRIMER_RIGHT_{sc}_SEQUENCE'],\n","                                   'stringency_level': stringency+1}\n","\n","            if (pt==3): #HAR-F\n","\n","              # saving a random \"good\" primer as a \"safety net\" in case we can not find any other in the exact position\n","              if safety_net_primer_forward == ():\n","                safety_net_primer_forward = primer['PRIMER_LEFT_0_SEQUENCE']\n","            \n","              temporary_name_string = f'PRIMER_LEFT_{sc}_SEQUENCE'\n","              primer_position = template.index(primer[temporary_name_string])\n","              if primer_position == 1303: # checking primer position\n","                primers_cleanup = {'Gene_ID': Gene_ID,  # if the position is correct we choose it!! --> we can now leave the while loop!\n","                                   'position':start_stop,\n","                                   'primer_type': primer_name[pt],\n","                                   \"primer_sequence\": primer[f'PRIMER_LEFT_{sc}_SEQUENCE'],\n","                                   'stringency_level': stringency+1}\n","       \n","        # TO DO: careful with stringency levels after extenstion\n","        if stringency == (stringency_levels-1) and primers_cleanup == (): # i.e. if we are at the last stringency and we still haven't left the loop....\n","          if (pt==2):\n","            if safety_net_primer_reverse == ():\n","              last_resort = template[1275:1300]\n","              primer_last_resort = revComp(last_resort)\n","              primers_cleanup = {'Gene_ID': Gene_ID,\n","                                  'position':start_stop,\n","                                  'primer_type': primer_name[pt],\n","                                  \"primer_sequence\": primer_last_resort,\n","                                  'stringency_level': \"25bp no conditions\"}\n","            else:\n","              safety_net_primer_reverse_t = revComp(safety_net_primer_reverse)\n","              net_position = template.index(safety_net_primer_reverse_t)\n","              extened_safety_net_rev_comp = template[net_position:1300]\n","              extended_safety_net_primer_reverse = revComp(extened_safety_net_rev_comp)\n","              primers_cleanup = {'Gene_ID': Gene_ID,\n","                                  'position':start_stop,\n","                                  'primer_type': primer_name[pt],\n","                                  \"primer_sequence\": extended_safety_net_primer_reverse,\n","                                  'stringency_level': f\"extended from {stringency+1}\"}\n","          if (pt==3):\n","            if safety_net_primer_forward == ():\n","              primers_cleanup = {'Gene_ID': Gene_ID,\n","                                  'position':start_stop,\n","                                  'primer_type': primer_name[pt],\n","                                  \"primer_sequence\": template[1303:1328],\n","                                  'stringency_level': \"25bp no conditions\"}\n","            else:\n","              net_position = template.index(safety_net_primer_forward)\n","              extension = template [1303:net_position]\n","              extended_safety_net_primer_forward = extension+safety_net_primer_forward\n","              primers_cleanup = {'Gene_ID': Gene_ID,\n","                                  'position':start_stop,\n","                                  'primer_type': primer_name[pt],\n","                                  \"primer_sequence\": extended_safety_net_primer_forward,\n","                                  'stringency_level': f\"extendedb from {stringency+1}\"}\n","\n","        if primers_cleanup == ():\n","          stringency +=1\n","        else:\n","          primers_cleanup_table = pd.DataFrame([primers_cleanup]) # coverting to dataframe\n","          primers_table = pd.concat([primers_table,primers_cleanup_table]) # extending existing list with dataframe that was just created\n","          stringency = stringency_levels # TO DO: SEE HOW TO MODIFY THIS NEXT\n","\n","      ########### normal cases #########\n","      if (pt == 0 or pt == 1 or pt == 4 or pt == 5):\n","        if primer_region == initial_primer_region:\n","          extension = 0\n","        else:\n","          extension = 1\n","\n","        primers_cleanup, warning_variable = DoIHaveAPrimer(extension,Gene_ID,start_stop,primer_type, primer_name[pt],stringency,primer)      # function 2 created by me \n","        \n","        if warning_variable == False: # i.e., if I do not get a warning then we are done --> we leave the while loop with \n","          primers_cleanup_table = pd.DataFrame([primers_cleanup]) # coverting to dataframe\n","          primers_table = pd.concat([primers_table,primers_cleanup_table]) # extending existing list with dataframe that was just created\n","          stringency = stringency_levels # leaving the loop\n","        else:\n","          if stringency == (stringency_levels-1):\n","            if primer_region == enlarged_primer_region:\n","              primers_cleanup = {'Gene_ID': Gene_ID,\n","                                  'position':start_stop,\n","                                  'primer_type': primer_name[pt],\n","                                  \"primer_sequence\": \"primer could not be calculated\",\n","                                  'stringency_level': \"NA\"}\n","              stringency = stringency_levels # leaving the loop\n","\n","            elif primer_region == initial_primer_region:\n","              stringency = 0  \n","              primer_region = enlarged_primer_region\n","          else:\n","            stringency +=1\n","\n","  return(primers_table)    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L9TtNu2NqVZt"},"outputs":[],"source":["# CONDITIONS VARIABLES - [stringent[min,opt,max], relaxed, desperate]\n","\n","#primer_position = [\"start(ATG)\",\"stop\"]\n","\n","primer_name = [\"val-F\",\"HAL-F\",\"HAL-R\",\"HAR-F\",\"HAR-R\",\"val-R\"]\n","initial_primer_region = [[0,100],[200,200],[1270,29],[1303,30],[2200,200],[2500,100]]\n","extended_primer_region = [[0,100],[200,300],[1270,29],[1303,30],[2200,200],[2500,100]]\n","\n","GC_content = [[30,50,70],[25,50,75],[20,50,80]]\n","size = [[18,20,25],[18,20,26],[17,20,30]]\n","max_end_GC = [3,4,4]\n","GC_clamp = [1,1,0]\n","TH_max_hairpin = [47.00,48.00,72.00]\n","max_polyx = [5,6,8] \n","stringency_levels = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kXrVus0JyJ_7"},"outputs":[],"source":["TFsdf = TFsdf.reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"94vWJ5VErNIX"},"outputs":[],"source":["primers_table = ()\n","primers_table = pd.DataFrame(primers_table)\n","\n","for x in tqdm(range(264,266)):   #len(TFsdf[\"Gene_ID\"])\n","  single = SixPrimersCalculator(TFsdf[\"Gene_ID\"][x],TFsdf[\"Gene_Region\"][x],TFsdf[\"Reference_Seq\"][x],primer_name,initial_primer_region,extended_primer_region, GC_content,size,max_end_GC,GC_clamp,TH_max_hairpin,max_polyx,stringency_levels)\n","  primers_table = pd.concat([primers_table,single])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ba9Dajcl9h3S"},"outputs":[],"source":["display(primers_table)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4TMOUuJ-FaK"},"outputs":[],"source":["primers_table.to_excel(\"output.xlsx\")  "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
